{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Anonymization Model Training Pipeline\n",
    "\n",
    "This notebook demonstrates how to fine-tune a T5 model for text anonymization using the Hugging Face ecosystem. The pipeline includes:\n",
    "\n",
    "1. Loading and preprocessing synthetic data\n",
    "2. Setting up the model and tokenizer\n",
    "3. Training configuration and process\n",
    "4. Model evaluation and metrics\n",
    "5. Inference examples\n",
    "\n",
    "## Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import torch\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# # Set random seed for reproducibility\n",
    "# torch.manual_seed(42)\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "We'll use our synthetic dataset from the Hugging Face Hub. This dataset contains pairs of original and anonymized texts, perfect for training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"kurkowski/synthetic-contextual-anonymizer-dataset\")\n",
    "\n",
    "print(\"Dataset Statistics:\")\n",
    "print(f\"Training examples: {len(dataset['train'])}\")\n",
    "print(f\"Validation examples: {len(dataset['validation'])}\")\n",
    "print(f\"Test examples: {len(dataset['test'])}\")\n",
    "\n",
    "# Display a sample\n",
    "print(\"\\nSample from training set:\")\n",
    "print(\"Original:\", dataset['train'][0]['context'])\n",
    "print(\"Anonymized:\", dataset['train'][0]['anonymized_context'])\n",
    "print(\"Used labels:\", dataset['train'][0]['used_labels'], type(dataset['train'][0]['used_labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Setup\n",
    "\n",
    "We'll use FLAN-T5-small as our base model. This is a good choice because:\n",
    "- It's relatively small and fast to train\n",
    "- It has good text-to-text capabilities\n",
    "- It's been trained on a variety of tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer and model\n",
    "model_name = \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "We need to convert our text examples into a format suitable for the model. This includes:\n",
    "- Adding a task-specific prompt\n",
    "- Tokenizing inputs and targets\n",
    "- Creating attention masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_labels(text):\n",
    "    \"\"\"\n",
    "    Usuwa numerację z etykiet (np. [NAME_1] -> [NAME]).\n",
    "    Obsługuje również etykiety z podkreślnikami w nazwie (np. POLICY_NUMBER).\n",
    "    \"\"\"\n",
    "    if isinstance(text, list):\n",
    "        return [normalize_labels(t) for t in text]\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    return re.sub(r'\\[([A-Z_]+)_\\d+\\]', r'[\\1]', text)\n",
    "\n",
    "def create_anonymization_prompt(labels):\n",
    "    \"\"\"Create a prompt for text anonymization task.\n",
    "    \n",
    "    Args:\n",
    "        labels: List of labels to use for anonymization\n",
    "        \n",
    "    Returns:\n",
    "        String containing the formatted prompt\n",
    "    \"\"\"\n",
    "    return f\"\"\"You are a text anonymization expert. Your task is to replace sensitive information with the following labels: { normalize_labels(labels)}.\n",
    "\n",
    "    Instructions:\n",
    "    1. Replace each sensitive information with appropriate label from the provided list\n",
    "    2. For multiple occurrences of the same type, use numbered labels (e.g. [NAME_1], [NAME_2])\n",
    "    3. Preserve the original text structure and meaning\n",
    "    4. Follow the examples precisely\n",
    "\n",
    "    Example:\n",
    "    Input: \"John Smith called Mary Johnson. John's number is 555-0123 and Mary's is 555-4567.\"\n",
    "    Output: \"[NAME_1] called [NAME_2]. [NAME_1]'s number is [PHONE_1] and [NAME_2]'s is [PHONE_2].\"\n",
    "\n",
    "    Task:\n",
    "    Anonymize the following text using only these labels: { normalize_labels(labels)}\n",
    "    Input: \n",
    "    \"\"\"\n",
    "\n",
    "def convert_examples_to_features(example_batch):\n",
    "    \"\"\"Convert text examples to model features.\n",
    "    \n",
    "    Args:\n",
    "        example_batch: Batch of examples from dataset\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with input_ids, attention_mask, and labels\n",
    "    \"\"\"\n",
    "    input_texts = []\n",
    "    for text, labels in zip(example_batch[\"context\"], example_batch[\"used_labels\"]):\n",
    "        prompt = create_anonymization_prompt(labels)\n",
    "        input_texts.append(prompt + text)\n",
    "    \n",
    "    print('input_texts:')\n",
    "    for text in input_texts[:3]:\n",
    "        print(text)\n",
    "    input_encodings = tokenizer(input_texts, truncation=True, padding=True)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        target_encodings = tokenizer(example_batch[\"anonymized_context\"], truncation=True, padding=True)\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": input_encodings[\"input_ids\"],\n",
    "        \"attention_mask\": input_encodings[\"attention_mask\"], \n",
    "        \"labels\": target_encodings[\"input_ids\"]\n",
    "    }\n",
    "\n",
    "test_prompt = create_anonymization_prompt(dataset['train'][0]['used_labels'])\n",
    "\n",
    "# Process all splits\n",
    "processed_dataset = dataset.map(\n",
    "    convert_examples_to_features,\n",
    "    batched=True,\n",
    "    desc=\"Processing dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_anonymization(text_to_anonymize, labels):\n",
    "    prompt = create_anonymization_prompt(labels)\n",
    "    print(prompt + text_to_anonymize)\n",
    "    inputs = tokenizer(\n",
    "        prompt + text_to_anonymize, \n",
    "        return_tensors=\"pt\",  # Tutaj jest OK używać return_tensors=\"pt\"\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_length=512,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "print(test_anonymization(processed_dataset['train'][0]['context'], processed_dataset['train'][0]['used_labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Configuration\n",
    "\n",
    "We'll configure the training process with optimal parameters for our task. Key considerations include:\n",
    "- Memory efficiency (batch size and gradient accumulation)\n",
    "- Learning rate and warmup\n",
    "- Evaluation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "trainer_args = TrainingArguments(\n",
    "    output_dir = \"anonymizer_model\", \n",
    "    num_train_epochs=3, \n",
    "    warmup_steps = 500,\n",
    "    per_device_train_batch_size=4,      \n",
    "    per_device_eval_batch_size=4,      \n",
    "    weight_decay=0.01, \n",
    "    logging_steps=2,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=250,\n",
    "    save_steps=250,\n",
    "    gradient_accumulation_steps=2,      \n",
    "    learning_rate=5e-5,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_first_step=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    gradient_checkpointing=True,        \n",
    "    torch_compile=False,                \n",
    "    dataloader_pin_memory=False,      \n",
    "    torch_empty_cache_steps=2         \n",
    ")\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "if hasattr(torch.mps, 'empty_cache'):\n",
    "    torch.mps.empty_cache()\n",
    "\n",
    "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=trainer_args,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=seq2seq_data_collator,\n",
    "    train_dataset=processed_dataset[\"train\"],\n",
    "    eval_dataset=processed_dataset[\"validation\"]\n",
    ")\n",
    "\n",
    "\n",
    "train_result =trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation\n",
    "\n",
    "We'll evaluate our model using:\n",
    "- Loss on test set\n",
    "- Custom metrics (Precision, Recall, F1) for entity anonymization\n",
    "- Visualization of training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
